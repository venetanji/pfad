{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Week 04: User Input and Audio\n",
    "\n",
    "This notebook covers the key concepts and practical applications for Week 4, including:\n",
    "- Streamlit user input handling (chat inputs, text inputs, buttons)\n",
    "- Audio recording and playback\n",
    "- Text-to-speech (TTS) and voice cloning\n",
    "- Real-time audio processing with PyAudio\n",
    "- Interactive voice applications\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Create interactive Streamlit applications with various user input methods\n",
    "2. Record and play audio in web applications\n",
    "3. Implement text-to-speech functionality\n",
    "4. Work with real-time audio streams\n",
    "5. Build voice-enabled chatbots and interactive applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install the required libraries for this week's examples. Note that some examples require external services or specific hardware configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install streamlit pandas numpy streamlit-audiorec torch pyaudio matplotlib\n",
    "\n",
    "# For TTS functionality (optional, requires external API)\n",
    "# !pip install coqui-tts requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Audio-related imports (may require additional setup)\n",
    "try:\n",
    "    import pyaudio\n",
    "    PYAUDIO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"PyAudio not available. Audio examples will be limited.\")\n",
    "    PYAUDIO_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from st_audiorec import st_audiorec\n",
    "    AUDIOREC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"streamlit-audiorec not available. Recording examples will be limited.\")\n",
    "    AUDIOREC_AVAILABLE = False\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user-input-section",
   "metadata": {},
   "source": [
    "## 2. Streamlit User Input Fundamentals\n",
    "\n",
    "Streamlit provides various ways to capture user input. Let's explore the most common methods used in interactive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-input-subsection",
   "metadata": {},
   "source": [
    "### 2.1 Basic Chat Input\n",
    "\n",
    "The simplest form of user input in Streamlit is the chat input widget. Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-chat-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic User Input (from 1_user_input.py)\n",
    "'''\n",
    "import streamlit as st\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "'''\n",
    "\n",
    "print(\"This example shows the simplest chat input.\")\n",
    "print(\"When run in Streamlit, it displays an input field at the bottom of the page.\")\n",
    "print(\"When the user types and presses Enter, the message is displayed as a chat bubble.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-history-subsection",
   "metadata": {},
   "source": [
    "### 2.2 Chat Input with Message History\n",
    "\n",
    "For more sophisticated applications, we want to maintain conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-with-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: User Input with History (from 2_user_input_with_history.py)\n",
    "'''\n",
    "import streamlit as st\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "'''\n",
    "\n",
    "print(\"This example demonstrates:\")\n",
    "print(\"1. Using st.session_state to maintain conversation history\")\n",
    "print(\"2. Displaying all previous messages when the page reloads\")\n",
    "print(\"3. Adding new messages to the conversation history\")\n",
    "print(\"4. Using message roles ('user' and 'assistant') for different styling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-inputs-subsection",
   "metadata": {},
   "source": [
    "### 2.3 Other Input Methods\n",
    "\n",
    "Streamlit offers many other input widgets for different use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-input-methods",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of various Streamlit input methods\n",
    "print(\"Common Streamlit input widgets:\")\n",
    "print(\"\")\n",
    "\n",
    "# Text inputs\n",
    "print(\"1. Text Inputs:\")\n",
    "print('   st.text_input(\"Enter text\")  # Single line text')\n",
    "print('   st.text_area(\"Enter text\")   # Multi-line text')\n",
    "print('   st.chat_input()             # Chat-style input')\n",
    "print(\"\")\n",
    "\n",
    "# Buttons and selections\n",
    "print(\"2. Buttons and Selections:\")\n",
    "print('   st.button(\"Click me\")       # Basic button')\n",
    "print('   st.selectbox(\"Choose\", options)  # Dropdown')\n",
    "print('   st.multiselect(\"Choose multiple\", options)  # Multi-select')\n",
    "print('   st.radio(\"Pick one\", options)  # Radio buttons')\n",
    "print('   st.checkbox(\"Check me\")     # Checkbox')\n",
    "print(\"\")\n",
    "\n",
    "# Numeric inputs\n",
    "print(\"3. Numeric Inputs:\")\n",
    "print('   st.number_input(\"Number\")   # Number input')\n",
    "print('   st.slider(\"Value\", 0, 100)  # Slider')\n",
    "print(\"\")\n",
    "\n",
    "# File and media inputs\n",
    "print(\"4. File and Media Inputs:\")\n",
    "print('   st.file_uploader(\"Upload\")  # File upload')\n",
    "print('   st.camera_input(\"Photo\")    # Camera input')\n",
    "print('   st_audiorec()              # Audio recording (requires streamlit-audiorec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-section",
   "metadata": {},
   "source": [
    "## 3. Audio Recording and Playback\n",
    "\n",
    "Working with audio in web applications involves recording, processing, and playing back audio data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-recording-subsection",
   "metadata": {},
   "source": [
    "### 3.1 Audio Recording with Streamlit\n",
    "\n",
    "The `st_audiorec` component allows users to record audio directly in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-recording-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording demonstration\n",
    "print(\"Audio Recording with streamlit-audiorec:\")\n",
    "print(\"\")\n",
    "\n",
    "if AUDIOREC_AVAILABLE:\n",
    "    print(\"✓ streamlit-audiorec is available\")\n",
    "    print(\"\")\n",
    "    print(\"Basic usage:\")\n",
    "    print('from st_audiorec import st_audiorec')\n",
    "    print('recording = st_audiorec()')\n",
    "    print('if recording:')\n",
    "    print('    # recording contains the audio data as bytes')\n",
    "    print('    with open(\"recorded_audio.wav\", \"wb\") as f:')\n",
    "    print('        f.write(recording)')\n",
    "else:\n",
    "    print(\"⚠ streamlit-audiorec not available\")\n",
    "    print(\"Install with: pip install streamlit-audiorec\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Features of st_audiorec:\")\n",
    "print(\"- Browser-based recording (no external software needed)\")\n",
    "print(\"- Returns audio data as bytes\")\n",
    "print(\"- Supports various audio formats\")\n",
    "print(\"- Works on most modern browsers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-playback-subsection",
   "metadata": {},
   "source": [
    "### 3.2 Audio Playback in Streamlit\n",
    "\n",
    "Streamlit provides built-in audio playback capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-playback-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio playback demonstration\n",
    "print(\"Audio Playback in Streamlit:\")\n",
    "print(\"\")\n",
    "print(\"Basic usage:\")\n",
    "print('st.audio(audio_file, format=\"audio/wav\")')\n",
    "print(\"\")\n",
    "print(\"Supported inputs:\")\n",
    "print(\"- File path (string): st.audio('path/to/audio.wav')\")\n",
    "print(\"- Bytes data: st.audio(audio_bytes)\")\n",
    "print(\"- NumPy array: st.audio(audio_array, sample_rate=44100)\")\n",
    "print(\"\")\n",
    "print(\"Supported formats:\")\n",
    "print(\"- WAV: format='audio/wav'\")\n",
    "print(\"- MP3: format='audio/mp3'\")\n",
    "print(\"- OGG: format='audio/ogg'\")\n",
    "print(\"\")\n",
    "\n",
    "# Create a simple sine wave for demonstration\n",
    "sample_rate = 44100\n",
    "duration = 2  # seconds\n",
    "frequency = 440  # A4 note\n",
    "\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "sine_wave = 0.3 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "print(f\"Generated a {duration}s sine wave at {frequency}Hz\")\n",
    "print(f\"Audio array shape: {sine_wave.shape}\")\n",
    "print(f\"Sample rate: {sample_rate}Hz\")\n",
    "print(\"\")\n",
    "print(\"In Streamlit, you would play this with:\")\n",
    "print(f\"st.audio(sine_wave, sample_rate={sample_rate})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tts-section",
   "metadata": {},
   "source": [
    "## 4. Text-to-Speech and Voice Cloning\n",
    "\n",
    "The repository includes examples of text-to-speech (TTS) functionality and voice cloning using external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tts-basic-subsection",
   "metadata": {},
   "source": [
    "### 4.1 Basic Text-to-Speech\n",
    "\n",
    "The `tts.py` example shows how to convert text to speech using an external API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tts-basic-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic TTS example (from week05/tts.py)\n",
    "print(\"Basic Text-to-Speech Example:\")\n",
    "print(\"\")\n",
    "print(\"Code structure:\")\n",
    "print('import streamlit as st')\n",
    "print('import uuid')\n",
    "print('import requests')\n",
    "print(\"\")\n",
    "print('if text := st.text_input(\"Enter text to convert to speech\", \"Hello, how are you?\"):')\n",
    "print('    tmp_file = f\"samples/tmp{uuid.uuid1()}.wav\"')\n",
    "print('    response = requests.post(')\n",
    "print('        \"http://localhost:8000/tts\",')\n",
    "print('        params={\"text\": text},')\n",
    "print('        stream=True,')\n",
    "print('    )')\n",
    "print('    ')\n",
    "print('    with open(tmp_file, \"wb\") as f:')\n",
    "print('        for chunk in response.iter_content(chunk_size=1024):')\n",
    "print('            f.write(chunk)')\n",
    "print('    ')\n",
    "print('    st.audio(tmp_file, format=\"audio/wav\")')\n",
    "print(\"\")\n",
    "print(\"Key concepts:\")\n",
    "print(\"1. User enters text via st.text_input()\")\n",
    "print(\"2. Text is sent to TTS API endpoint\")\n",
    "print(\"3. Audio response is saved to temporary file\")\n",
    "print(\"4. Audio is played back using st.audio()\")\n",
    "print(\"5. UUID ensures unique filenames for concurrent users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voice-cloning-subsection",
   "metadata": {},
   "source": [
    "### 4.2 Voice Cloning with Audio Input\n",
    "\n",
    "The `tts_wav.py` example demonstrates voice cloning by combining text input with voice recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voice-cloning-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice cloning example (from week04/tts_wav.py)\n",
    "print(\"Voice Cloning Example:\")\n",
    "print(\"\")\n",
    "print(\"Code structure:\")\n",
    "print('import streamlit as st')\n",
    "print('from st_audiorec import st_audiorec')\n",
    "print('import torch')\n",
    "print('import uuid')\n",
    "print('import requests')\n",
    "print(\"\")\n",
    "print('device = \"cuda\" if torch.cuda.is_available() else \"cpu\"')\n",
    "print(\"\")\n",
    "print('\"Record your voice to clone it\"')\n",
    "print('recording = st_audiorec()')\n",
    "print(\"\")\n",
    "print('\"Synthesize voice\"')\n",
    "print('if text := st.text_input(\"Enter text to convert to speech\"):')\n",
    "print('    options = {\"text\": text, \"language\": \"en\"}')\n",
    "print('    ')\n",
    "print('    if recording:')\n",
    "print('        voice_file = f\"samples/voice-{uuid.uuid1()}.wav\"')\n",
    "print('        with open(voice_file, \"wb\") as f:')\n",
    "print('            f.write(recording)')\n",
    "print('        options[\"speaker_wav\"] = voice_file')\n",
    "print('    ')\n",
    "print('    response = requests.post(')\n",
    "print('        \"http://localhost:8000/generate_audio\",')\n",
    "print('        json=options,')\n",
    "print('    )')\n",
    "print('    ')\n",
    "print('    st.audio(response.json().get(\"file_path\"), format=\"audio/wav\")')\n",
    "print(\"\")\n",
    "print(\"Voice cloning workflow:\")\n",
    "print(\"1. User records their voice using st_audiorec()\")\n",
    "print(\"2. User enters text to be synthesized\")\n",
    "print(\"3. Both audio sample and text are sent to the API\")\n",
    "print(\"4. API clones the voice and generates speech\")\n",
    "print(\"5. Result is played back to the user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pyaudio-section",
   "metadata": {},
   "source": [
    "## 5. Real-time Audio Processing with PyAudio\n",
    "\n",
    "PyAudio enables real-time audio processing, including recording, playback, and audio effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pyaudio-basic-subsection",
   "metadata": {},
   "source": [
    "### 5.1 Audio Loopback Example\n",
    "\n",
    "The simplest PyAudio example is an audio loopback that captures input and immediately plays it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pyaudio-loopback-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyAudio loopback example (from week06/4_pyaudio_loopback.py)\n",
    "print(\"PyAudio Loopback Example:\")\n",
    "print(\"\")\n",
    "if PYAUDIO_AVAILABLE:\n",
    "    print(\"✓ PyAudio is available\")\n",
    "else:\n",
    "    print(\"⚠ PyAudio not available\")\n",
    "    print(\"Install with: pip install pyaudio\")\n",
    "    print(\"Note: May require additional system dependencies\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Code structure:\")\n",
    "print('import pyaudio')\n",
    "print(\"\")\n",
    "print('# Audio parameters')\n",
    "print('CHUNK = 256        # Buffer size')\n",
    "print('FORMAT = pyaudio.paInt16  # 16-bit audio')\n",
    "print('CHANNELS = 1       # Mono audio')\n",
    "print('RATE = 44100       # Sample rate (Hz)')\n",
    "print(\"\")\n",
    "print('# Initialize PyAudio')\n",
    "print('p = pyaudio.PyAudio()')\n",
    "print(\"\")\n",
    "print('# Open input and output streams')\n",
    "print('input_stream = p.open(format=FORMAT, channels=CHANNELS,')\n",
    "print('                      rate=RATE, input=True,')\n",
    "print('                      frames_per_buffer=CHUNK)')\n",
    "print('output_stream = p.open(format=FORMAT, channels=CHANNELS,')\n",
    "print('                       rate=RATE, output=True,')\n",
    "print('                       frames_per_buffer=CHUNK)')\n",
    "print(\"\")\n",
    "print('# Main loop')\n",
    "print('while True:')\n",
    "print('    data = input_stream.read(CHUNK)')\n",
    "print('    output_stream.write(data)')\n",
    "print(\"\")\n",
    "print(\"Key concepts:\")\n",
    "print(\"1. CHUNK size determines latency vs. CPU usage\")\n",
    "print(\"2. FORMAT specifies bit depth and encoding\")\n",
    "print(\"3. RATE is the sampling frequency\")\n",
    "print(\"4. Separate streams for input and output\")\n",
    "print(\"5. Real-time processing in main loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audio-params-subsection",
   "metadata": {},
   "source": [
    "### 5.2 Understanding Audio Parameters\n",
    "\n",
    "Let's explore the key parameters used in audio processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "audio-params-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio parameters explanation\n",
    "print(\"Audio Parameters in Digital Audio:\")\n",
    "print(\"\")\n",
    "\n",
    "# Sample rate\n",
    "print(\"1. Sample Rate (Hz):\")\n",
    "print(\"   - Determines audio quality and frequency range\")\n",
    "print(\"   - 44100 Hz: CD quality, captures up to ~22kHz\")\n",
    "print(\"   - 48000 Hz: Professional audio standard\")\n",
    "print(\"   - 16000 Hz: Speech applications (saves bandwidth)\")\n",
    "print(\"\")\n",
    "\n",
    "# Bit depth\n",
    "print(\"2. Bit Depth (Format):\")\n",
    "print(\"   - paInt16: 16-bit integers (-32768 to 32767)\")\n",
    "print(\"   - paInt32: 32-bit integers (higher dynamic range)\")\n",
    "print(\"   - paFloat32: 32-bit floating point (-1.0 to 1.0)\")\n",
    "print(\"\")\n",
    "\n",
    "# Channels\n",
    "print(\"3. Channels:\")\n",
    "print(\"   - 1: Mono audio\")\n",
    "print(\"   - 2: Stereo audio (left/right)\")\n",
    "print(\"   - More: Surround sound systems\")\n",
    "print(\"\")\n",
    "\n",
    "# Buffer size\n",
    "print(\"4. Buffer Size (CHUNK):\")\n",
    "print(\"   - Smaller: Lower latency, higher CPU usage\")\n",
    "print(\"   - Larger: Higher latency, lower CPU usage\")\n",
    "print(\"   - Typical values: 128, 256, 512, 1024 samples\")\n",
    "print(\"\")\n",
    "\n",
    "# Calculate some examples\n",
    "sample_rates = [16000, 44100, 48000]\n",
    "chunk_sizes = [128, 256, 512]\n",
    "\n",
    "print(\"Latency calculations (buffer_size / sample_rate):\")\n",
    "for rate in sample_rates:\n",
    "    for chunk in chunk_sizes:\n",
    "        latency_ms = (chunk / rate) * 1000\n",
    "        print(f\"   {chunk} samples @ {rate}Hz = {latency_ms:.1f}ms latency\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waveform-visualization-subsection",
   "metadata": {},
   "source": [
    "### 5.3 Real-time Waveform Visualization\n",
    "\n",
    "The repository includes an advanced example that visualizes audio waveforms in real-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waveform-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time waveform visualization (from week06/6_waveform.py)\n",
    "print(\"Real-time Waveform Visualization:\")\n",
    "print(\"\")\n",
    "print(\"This example combines:\")\n",
    "print(\"1. PyAudio for real-time audio capture\")\n",
    "print(\"2. NumPy for audio data processing\")\n",
    "print(\"3. Matplotlib for real-time plotting\")\n",
    "print(\"4. AsyncIO for concurrent processing\")\n",
    "print(\"\")\n",
    "print(\"Key components:\")\n",
    "print(\"\")\n",
    "print(\"Audio callback function:\")\n",
    "print('def input_callback(in_data, frame_count, time_info, status):')\n",
    "print('    audio_queue.put_nowait(in_data)')\n",
    "print('    return (None, pyaudio.paContinue)')\n",
    "print(\"\")\n",
    "print(\"Rolling buffer for waveform display:\")\n",
    "print('ROLLING_WINDOW = 4 * RATE  # 4 seconds of audio')\n",
    "print('buffer = np.zeros(ROLLING_WINDOW, dtype=np.int16)')\n",
    "print(\"\")\n",
    "print(\"Processing audio data:\")\n",
    "print('data = audio_queue.get_nowait()')\n",
    "print('waveform = np.frombuffer(data, dtype=np.int16)')\n",
    "print('buffer = np.roll(buffer, -len(waveform))')\n",
    "print('buffer[-len(waveform):] = waveform')\n",
    "print(\"\")\n",
    "print(\"Real-time plotting:\")\n",
    "print('def update_frame(frame):')\n",
    "print('    line.set_ydata(buffer)')\n",
    "print('    return line,')\n",
    "print('anim = animation.FuncAnimation(fig, update_frame, interval=50)')\n",
    "print(\"\")\n",
    "print(\"Technical concepts:\")\n",
    "print(\"- Stream callbacks for low-latency audio\")\n",
    "print(\"- Circular/rolling buffers for continuous data\")\n",
    "print(\"- Real-time plotting with matplotlib animation\")\n",
    "print(\"- Asynchronous processing with asyncio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises-section",
   "metadata": {},
   "source": [
    "## 6. Practical Exercises and Activities\n",
    "\n",
    "Here are some hands-on exercises to practice the concepts covered in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "### Exercise 1: Enhanced Chat Application\n",
    "\n",
    "Create a Streamlit chat application with the following features:\n",
    "- Message history persistence\n",
    "- User name input\n",
    "- Timestamp for each message\n",
    "- Message export functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-1-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Template\n",
    "print(\"Exercise 1: Enhanced Chat Application\")\n",
    "print(\"\")\n",
    "print(\"Create a file 'enhanced_chat.py' with the following structure:\")\n",
    "print(\"\")\n",
    "print('import streamlit as st')\n",
    "print('import datetime')\n",
    "print('import json')\n",
    "print(\"\")\n",
    "print('st.title(\"Enhanced Chat Application\")')\n",
    "print(\"\")\n",
    "print('# TODO: Add user name input')\n",
    "print('# username = st.text_input(\"Enter your name:\", \"Anonymous\")')\n",
    "print(\"\")\n",
    "print('# TODO: Initialize message history with timestamps')\n",
    "print('# if \"messages\" not in st.session_state:')\n",
    "print('#     st.session_state.messages = []')\n",
    "print(\"\")\n",
    "print('# TODO: Display messages with timestamps and usernames')\n",
    "print(\"\")\n",
    "print('# TODO: Add new messages with metadata')\n",
    "print('# if prompt := st.chat_input():')\n",
    "print('#     message = {')\n",
    "print('#         \"user\": username,')\n",
    "print('#         \"content\": prompt,')\n",
    "print('#         \"timestamp\": datetime.datetime.now().isoformat()')\n",
    "print('#     }')\n",
    "print('#     st.session_state.messages.append(message)')\n",
    "print(\"\")\n",
    "print('# TODO: Add export functionality')\n",
    "print('# if st.button(\"Export Chat\"):')\n",
    "print('#     chat_json = json.dumps(st.session_state.messages, indent=2)')\n",
    "print('#     st.download_button(\"Download Chat\", chat_json, \"chat_export.json\")')\n",
    "print(\"\")\n",
    "print(\"Run with: streamlit run enhanced_chat.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### Exercise 2: Audio Recorder and Analyzer\n",
    "\n",
    "Build an application that records audio and displays basic analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-2-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Template\n",
    "print(\"Exercise 2: Audio Recorder and Analyzer\")\n",
    "print(\"\")\n",
    "print(\"Create a file 'audio_analyzer.py' that:\")\n",
    "print(\"1. Records audio using st_audiorec\")\n",
    "print(\"2. Converts audio to numpy array\")\n",
    "print(\"3. Displays waveform plot\")\n",
    "print(\"4. Shows basic statistics (duration, peak amplitude, etc.)\")\n",
    "print(\"\")\n",
    "print(\"Key functions to implement:\")\n",
    "print(\"\")\n",
    "print('def bytes_to_numpy(audio_bytes):')\n",
    "print('    \"\"\"Convert audio bytes to numpy array\"\"\"')\n",
    "print('    # TODO: Use wave module or numpy.frombuffer')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print('def plot_waveform(audio_array, sample_rate=44100):')\n",
    "print('    \"\"\"Plot audio waveform\"\"\"')\n",
    "print('    # TODO: Create time axis and plot with matplotlib')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print('def analyze_audio(audio_array, sample_rate=44100):')\n",
    "print('    \"\"\"Calculate audio statistics\"\"\"')\n",
    "print('    # TODO: Calculate duration, peak, RMS, etc.')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print(\"Bonus features:\")\n",
    "print(\"- Frequency spectrum analysis\")\n",
    "print(\"- Audio filtering (low-pass, high-pass)\")\n",
    "print(\"- Export processed audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3",
   "metadata": {},
   "source": [
    "### Exercise 3: Voice-Controlled Calculator\n",
    "\n",
    "Combine speech recognition with text-to-speech for a voice-controlled calculator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exercise-3-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Template\n",
    "print(\"Exercise 3: Voice-Controlled Calculator\")\n",
    "print(\"\")\n",
    "print(\"Create a calculator that:\")\n",
    "print(\"1. Accepts voice input for mathematical expressions\")\n",
    "print(\"2. Processes the speech to extract numbers and operations\")\n",
    "print(\"3. Calculates the result\")\n",
    "print(\"4. Speaks the result back to the user\")\n",
    "print(\"\")\n",
    "print(\"Required components:\")\n",
    "print(\"\")\n",
    "print('def speech_to_text(audio_bytes):')\n",
    "print('    \"\"\"Convert speech to text (requires speech recognition API)\"\"\"')\n",
    "print('    # TODO: Implement using external service')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print('def parse_math_expression(text):')\n",
    "print('    \"\"\"Extract mathematical expression from text\"\"\"')\n",
    "print('    # TODO: Handle \"two plus three\", \"5 times 7\", etc.')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print('def calculate(expression):')\n",
    "print('    \"\"\"Safely evaluate mathematical expression\"\"\"')\n",
    "print('    # TODO: Use ast.literal_eval or similar safe method')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print('def text_to_speech(text):')\n",
    "print('    \"\"\"Convert result to speech\"\"\"')\n",
    "print('    # TODO: Use TTS API from earlier examples')\n",
    "print('    pass')\n",
    "print(\"\")\n",
    "print(\"Example workflow:\")\n",
    "print('User says: \"What is five plus three?\"')\n",
    "print('System responds: \"Five plus three equals eight\"')\n",
    "print(\"\")\n",
    "print(\"Challenges:\")\n",
    "print(\"- Handling different ways to express numbers\")\n",
    "print(\"- Robust parsing of mathematical operations\")\n",
    "print(\"- Error handling for invalid expressions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integration-section",
   "metadata": {},
   "source": [
    "## 7. Integration Patterns and Best Practices\n",
    "\n",
    "When building applications that combine user input and audio, consider these patterns and practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state-management-subsection",
   "metadata": {},
   "source": [
    "### 7.1 State Management in Streamlit\n",
    "\n",
    "Managing application state is crucial for interactive applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "state-management-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State management best practices\n",
    "print(\"Streamlit State Management Best Practices:\")\n",
    "print(\"\")\n",
    "print(\"1. Initialize state with default values:\")\n",
    "print('if \"key\" not in st.session_state:')\n",
    "print('    st.session_state.key = default_value')\n",
    "print(\"\")\n",
    "print(\"2. Use descriptive keys:\")\n",
    "print('st.session_state.chat_messages  # Good')\n",
    "print('st.session_state.msgs          # Avoid')\n",
    "print(\"\")\n",
    "print(\"3. Group related state:\")\n",
    "print('if \"app_state\" not in st.session_state:')\n",
    "print('    st.session_state.app_state = {')\n",
    "print('        \"user_name\": \"\",')\n",
    "print('        \"messages\": [],')\n",
    "print('        \"settings\": {}')\n",
    "print('    }')\n",
    "print(\"\")\n",
    "print(\"4. Reset state when needed:\")\n",
    "print('if st.button(\"Reset Chat\"):')\n",
    "print('    st.session_state.messages = []')\n",
    "print('    st.rerun()  # Refresh the app')\n",
    "print(\"\")\n",
    "print(\"5. Avoid storing large objects:\")\n",
    "print('# Store file paths, not file contents')\n",
    "print('st.session_state.audio_file_path = \"temp/audio.wav\"')\n",
    "print('# Not: st.session_state.audio_data = large_audio_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-handling-subsection",
   "metadata": {},
   "source": [
    "### 7.2 Error Handling and User Feedback\n",
    "\n",
    "Robust error handling improves user experience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error-handling-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling patterns\n",
    "print(\"Error Handling and User Feedback Patterns:\")\n",
    "print(\"\")\n",
    "print(\"1. API call error handling:\")\n",
    "print('try:')\n",
    "print('    response = requests.post(api_url, json=data, timeout=30)')\n",
    "print('    response.raise_for_status()')\n",
    "print('    return response.json()')\n",
    "print('except requests.exceptions.Timeout:')\n",
    "print('    st.error(\"Request timed out. Please try again.\")')\n",
    "print('except requests.exceptions.ConnectionError:')\n",
    "print('    st.error(\"Cannot connect to service. Check your connection.\")')\n",
    "print('except requests.exceptions.HTTPError as e:')\n",
    "print('    st.error(f\"Service error: {e}\")')\n",
    "print(\"\")\n",
    "print(\"2. Audio processing error handling:\")\n",
    "print('try:')\n",
    "print('    if not PYAUDIO_AVAILABLE:')\n",
    "print('        st.warning(\"PyAudio not available. Install with: pip install pyaudio\")')\n",
    "print('        return')\n",
    "print('    ')\n",
    "print('    # Audio processing code')\n",
    "print('except OSError as e:')\n",
    "print('    st.error(f\"Audio device error: {e}\")')\n",
    "print('    st.info(\"Check that your microphone is connected and working.\")')\n",
    "print(\"\")\n",
    "print(\"3. User input validation:\")\n",
    "print('if not text.strip():')\n",
    "print('    st.warning(\"Please enter some text.\")')\n",
    "print('    return')\n",
    "print('if len(text) > 1000:')\n",
    "print('    st.error(\"Text too long. Maximum 1000 characters.\")')\n",
    "print('    return')\n",
    "print(\"\")\n",
    "print(\"4. Progress indicators:\")\n",
    "print('with st.spinner(\"Processing audio...\"):')\n",
    "print('    result = process_audio(audio_data)')\n",
    "print('st.success(\"Audio processed successfully!\")')\n",
    "print(\"\")\n",
    "print(\"5. Graceful degradation:\")\n",
    "print('if AUDIOREC_AVAILABLE:')\n",
    "print('    recording = st_audiorec()')\n",
    "print('else:')\n",
    "print('    st.info(\"Audio recording not available.\")')\n",
    "print('    uploaded_file = st.file_uploader(\"Upload audio file\", type=[\"wav\", \"mp3\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-subsection",
   "metadata": {},
   "source": [
    "### 7.3 Performance Considerations\n",
    "\n",
    "Audio applications can be resource-intensive. Here are optimization strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization tips\n",
    "print(\"Performance Optimization for Audio Applications:\")\n",
    "print(\"\")\n",
    "print(\"1. Cache expensive operations:\")\n",
    "print('@st.cache_data')\n",
    "print('def load_audio_model():')\n",
    "print('    # Load model once, cache for subsequent uses')\n",
    "print('    return model')\n",
    "print(\"\")\n",
    "print(\"2. Use appropriate audio parameters:\")\n",
    "print('# For speech: lower sample rate saves bandwidth')\n",
    "print('SPEECH_RATE = 16000')\n",
    "print('# For music: higher sample rate for quality')\n",
    "print('MUSIC_RATE = 44100')\n",
    "print(\"\")\n",
    "print(\"3. Limit audio duration:\")\n",
    "print('MAX_RECORDING_SECONDS = 30')\n",
    "print('if audio_duration > MAX_RECORDING_SECONDS:')\n",
    "print('    st.warning(f\"Audio too long. Maximum {MAX_RECORDING_SECONDS} seconds.\")')\n",
    "print(\"\")\n",
    "print(\"4. Use streaming for large files:\")\n",
    "print('def stream_audio_to_api(audio_data):')\n",
    "print('    with requests.post(url, stream=True) as response:')\n",
    "print('        for chunk in response.iter_content(chunk_size=8192):')\n",
    "print('            yield chunk')\n",
    "print(\"\")\n",
    "print(\"5. Clean up temporary files:\")\n",
    "print('import tempfile')\n",
    "print('import os')\n",
    "print(\"\")\n",
    "print('with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:')\n",
    "print('    tmp_file.write(audio_data)')\n",
    "print('    tmp_path = tmp_file.name')\n",
    "print(\"\")\n",
    "print('try:')\n",
    "print('    # Process audio file')\n",
    "print('    result = process_audio_file(tmp_path)')\n",
    "print('finally:')\n",
    "print('    os.unlink(tmp_path)  # Clean up')\n",
    "print(\"\")\n",
    "print(\"6. Memory management for real-time audio:\")\n",
    "print('# Use circular buffers instead of growing lists')\n",
    "print('from collections import deque')\n",
    "print('audio_buffer = deque(maxlen=sample_rate * 10)  # 10 seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Next Steps\n",
    "\n",
    "This notebook covered the essential concepts for building interactive applications with user input and audio processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-subsection",
   "metadata": {},
   "source": [
    "### Summary of Key Concepts\n",
    "\n",
    "1. **User Input Methods**:\n",
    "   - `st.chat_input()` for conversational interfaces\n",
    "   - `st.text_input()`, `st.text_area()` for text entry\n",
    "   - Various widgets for different input types\n",
    "   - Session state management for persistent data\n",
    "\n",
    "2. **Audio Recording and Playback**:\n",
    "   - `st_audiorec()` for browser-based recording\n",
    "   - `st.audio()` for playback in web apps\n",
    "   - Audio format considerations and conversions\n",
    "\n",
    "3. **Text-to-Speech and Voice Processing**:\n",
    "   - Integration with external TTS APIs\n",
    "   - Voice cloning with sample audio\n",
    "   - Real-time voice synthesis\n",
    "\n",
    "4. **Real-time Audio Processing**:\n",
    "   - PyAudio for low-level audio operations\n",
    "   - Stream callbacks and buffer management\n",
    "   - Real-time visualization and analysis\n",
    "\n",
    "5. **Best Practices**:\n",
    "   - Error handling and user feedback\n",
    "   - Performance optimization\n",
    "   - State management patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps-subsection",
   "metadata": {},
   "source": [
    "### Next Steps and Advanced Topics\n",
    "\n",
    "To continue developing your skills in user input and audio processing:\n",
    "\n",
    "1. **Explore Advanced Audio Processing**:\n",
    "   - Digital signal processing (DSP) techniques\n",
    "   - Audio effects and filters\n",
    "   - Fourier transforms for frequency analysis\n",
    "\n",
    "2. **Machine Learning Integration**:\n",
    "   - Speech recognition with models like Whisper\n",
    "   - Audio classification and analysis\n",
    "   - Real-time audio generation with AI models\n",
    "\n",
    "3. **Production Deployment**:\n",
    "   - Scaling audio applications\n",
    "   - Cloud audio processing services\n",
    "   - WebRTC for real-time communication\n",
    "\n",
    "4. **Mobile and Cross-Platform**:\n",
    "   - PWA (Progressive Web App) audio features\n",
    "   - Mobile-specific audio considerations\n",
    "   - Cross-browser compatibility\n",
    "\n",
    "5. **Security and Privacy**:\n",
    "   - Audio data encryption\n",
    "   - User consent and privacy policies\n",
    "   - Secure API communication\n",
    "\n",
    "Keep experimenting with the code examples and try building your own audio-enabled applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources-subsection",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- **Streamlit Documentation**: https://docs.streamlit.io/\n",
    "- **PyAudio Documentation**: https://people.csail.mit.edu/hubert/pyaudio/\n",
    "- **streamlit-audiorec**: https://github.com/stefanrmmr/streamlit-audio-recorder\n",
    "- **Coqui TTS**: https://github.com/coqui-ai/TTS\n",
    "- **Digital Signal Processing**: https://www.dspguide.com/\n",
    "- **Web Audio API**: https://developer.mozilla.org/en-US/Web_Audio_API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}