x-gpu: &x-gpu
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            capabilities: ["gpu"]  

services:
  bot:
    build: .
    volumes:
      - ./src/:/app
    depends_on:
      - ollama
    command: streamlit run app.py
    ports:
      - 8501:8501
    env_file:
      - .env
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - THREAD_ID=${THREAD_ID}

  ollama:
    <<: *x-gpu 
    image: ollama/ollama:latest
    volumes:
      - ollama:/root/.ollama
    ports:
      - 11434:11434
  
volumes:
  ollama: